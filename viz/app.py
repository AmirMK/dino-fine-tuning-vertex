# app.py
import pathlib
import pandas as pd
import streamlit as st
import plotly.express as px
from google.cloud import storage

st.set_page_config(page_title="Embedding Explorer", layout="wide")

# the list of embedding output generated by data_viz_prep
DEFAULT_CHOICES = [
    "fine_tunned_embeddings_v2.parquet",  # default
    "base_embeddings.parquet",
]
REQUIRED_COLS = ["file", "cluster", "dim1", "dim2"]

# GCS bucket where the images are stored
GCS_BUCKET = "my_dino_test"

# ---------- Data loaders ----------
@st.cache_data(show_spinner=False)
def load_df(p: str) -> pd.DataFrame:
    df = pd.read_parquet(p)
    missing = [c for c in REQUIRED_COLS if c not in df.columns]
    if missing:
        raise ValueError(f"Missing required columns: {missing}")
    return df

@st.cache_resource
def get_storage_client():
    # Uses Workbench/Service Account credentials in your environment
    return storage.Client()

@st.cache_data(show_spinner=False)
def fetch_image_bytes(bucket: str, blob_name: str) -> bytes:
    # Append .jpg if needed (remove if your 'file' already includes extension)
    name = blob_name if blob_name.lower().endswith(".jpg") else f"{blob_name}.jpg"
    client = get_storage_client()
    blob = client.bucket(bucket).blob(name)
    return blob.download_as_bytes()

# ---------- Sidebar: data source ----------
st.sidebar.header("Data")
path_mode = st.sidebar.radio("Pick data source", ["Default file", "Upload"], horizontal=True)

if path_mode == "Default file":
    parquet_path = st.sidebar.selectbox("Choose default Parquet file", DEFAULT_CHOICES, index=0)
    load_btn = st.sidebar.button("Load")
    if load_btn or parquet_path:
        try:
            df = load_df(parquet_path)
        except Exception as e:
            st.sidebar.error(f"Failed to load: {e}")
            st.stop()
else:
    up = st.sidebar.file_uploader("Upload a Parquet file", type=["parquet"])
    if up is None:
        st.info("Upload a file to continue.")
        st.stop()
    try:
        df = pd.read_parquet(up)
        missing = [c for c in REQUIRED_COLS if c not in df.columns]
        if missing:
            st.sidebar.error(f"Missing required columns: {missing}")
            st.stop()
    except Exception as e:
        st.sidebar.error(f"Failed to read parquet: {e}")
        st.stop()

# ---------- Prepare data ----------
df = df.copy()
extra_cols = [c for c in df.columns if c not in REQUIRED_COLS]
df = df[REQUIRED_COLS + extra_cols]
df["cluster"] = df["cluster"].astype(int)
df["dim1"] = pd.to_numeric(df["dim1"], errors="coerce")
df["dim2"] = pd.to_numeric(df["dim2"], errors="coerce")
df = df.dropna(subset=["dim1", "dim2"])

# ---------- Filters (controls what appears on the left plot only) ----------
st.sidebar.header("Filters")
clusters_plot = sorted(df["cluster"].unique().tolist())
if -1 in clusters_plot:
    include_noise = st.sidebar.checkbox("Include noise (cluster = -1)", value=False)
    filtered = df if include_noise else df[df["cluster"] != -1]
else:
    st.sidebar.caption("No noise cluster (-1) found in data.")
    filtered = df

# ---------- Display controls ----------
st.sidebar.header("Display")
max_pts = st.sidebar.number_input("Max points (sampling)", min_value=500, max_value=500_000, value=50_000, step=500)
if len(filtered) > max_pts:
    filtered = filtered.sample(n=max_pts, random_state=42)
size = st.sidebar.slider("Point size", 5, 35, 10)
opacity = st.sidebar.slider("Point opacity", 0.1, 1.0, 0.7)
st.sidebar.caption(f"Total rows: {len(df)} | After filters/sampling: {len(filtered)}")

# ---------- Main layout ----------
st.title("Embedding Explorer (dim1 vs dim2)")
left, right = st.columns([1, 1])

if filtered.empty:
    with left:
        st.warning(
            "No points to display. Try enabling **Include noise (-1)** or check your dim1/dim2 values."
        )
        st.write("Cluster counts (full data):", df["cluster"].value_counts(dropna=False))
    st.stop()

# Build figure (standard Plotly render)
plot_df = filtered.assign(cluster_str=filtered["cluster"].astype(str))
fig = px.scatter(
    plot_df,
    x="dim1",
    y="dim2",
    color="cluster_str",
    hover_name="cluster_str",
    hover_data=[],            # keep hover minimal
)
fig.update_traces(
    marker=dict(size=size, opacity=opacity, line=dict(width=1, color="black")),
    hovertemplate="cluster=%{hovertext}<extra></extra>",
)
fig.update_layout(
    legend_title_text="cluster",
    margin=dict(l=10, r=10, t=30, b=10),
    hovermode="closest",
    width=820,   # tune to fit the left column
    height=640,
    xaxis_title="umap-1",
    yaxis_title="umap-2",
    font=dict(size=16),  # increases overall font size (axes, legend, etc.)    
    xaxis=dict(
        title_font=dict(size=14, color="black"),   # axis label style
        tickfont=dict(size=14, color="black"),          # numbers on axis
        linecolor="black", linewidth=2,               # axis line thickness
        gridcolor="lightgray", gridwidth=2,            # grid line color + thickness
        showgrid = True
    ),
    yaxis=dict(
        title_font=dict(size=14, color="black"),
        tickfont=dict(size=14, color="black"),
        linecolor="black", linewidth=2,
        gridcolor="lightgray", gridwidth=2,
        showgrid = True
        
    )
)

with left:
    st.metric("Percentage of categorized images", f"{round((len(filtered)/3600)*100)}%")
    st.plotly_chart(fig, use_container_width=False)

# ---------- Right column: pick a cluster -> show 5 random images ----------
with right:
    st.subheader("Preview")

    # Use ALL clusters from the full dataframe (not just filtered plot)
    clusters_all = sorted(df["cluster"].unique().tolist())
    default_index = clusters_all.index(-1) if -1 in clusters_all else 0
    selected_cluster = st.selectbox("Pick a cluster to preview", clusters_all, index=default_index)

    # Seed for refreshing random sample
    if "preview_seed" not in st.session_state:
        st.session_state["preview_seed"] = 0

    # Button to refresh the selection
    if st.button("Refresh ðŸ”„"):
        st.session_state["preview_seed"] += 1

    cluster_subset = df[df["cluster"] == selected_cluster]["file"].astype(str)
    if cluster_subset.empty:
        st.caption("No images found for this cluster.")
    else:
        # Sample up to 6 images
        sample_n = min(6, len(cluster_subset))
        sampled_files = cluster_subset.sample(
            n=sample_n, random_state=st.session_state["preview_seed"]
        ).tolist()

        # Display as a 3x2 grid
        rows = 3
        cols_per_row = 3
        for r in range(rows):
            row_files = sampled_files[r * cols_per_row : (r + 1) * cols_per_row]
            cols = st.columns(cols_per_row)
            for c, fname in enumerate(row_files):
                try:
                    img_bytes = fetch_image_bytes(GCS_BUCKET, fname)
                    with cols[c]:                        
                        st.image(img_bytes, caption=fname, use_container_width=False, width=300)
                except Exception as e:
                    with cols[c]:
                        st.warning(f"Could not load: {fname}\n{e}")
